{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AMBevSZ-hYc0"
   },
   "source": [
    ">> **Machine Learning Academy : Seven Step Template **\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kI34491C3elh"
   },
   "source": [
    "<center><img src=\"https://www.dropbox.com/s/r86beo9nt8xrgh9/MLA%20Seven%20Step%20Process.png?raw=1\" height=300px width=1000px></img></center>\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cUnOm_5Sq8GT"
   },
   "source": [
    "# Step - 1 : Frame The Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9vQhQGknhXjO"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k2rVS7e_hYH_"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ne2-Ypwa4Hii"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QbYMguutw0U7"
   },
   "source": [
    "# Step - 2 : Obtain the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Rpa7e44q9hG"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DoloRktKqGbF"
   },
   "outputs": [],
   "source": [
    "#Installing modules we need. And doing it only once.\n",
    "import pkgutil; \n",
    "if not pkgutil.find_loader(\"torch\"):\n",
    "  !pip install torch -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R8l03wUUqGbO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8izv57KJfyHf"
   },
   "outputs": [],
   "source": [
    "torch.cuda.is_available() # verifies we have GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MksYS8zQigKr"
   },
   "source": [
    "### Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3fW_cUVM4Pz_"
   },
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/o13uszgy955mdh8/ml-100k.zip -q\n",
    "!unzip ml-100k.zip >0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FZxB9U-fNexf"
   },
   "outputs": [],
   "source": [
    "ls -l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q0p4YObz4hBf"
   },
   "outputs": [],
   "source": [
    "# Preparing the training set and the test set\n",
    "training_set_df = pd.read_csv('ml-100k/u1.base', delimiter = '\\t',names=\"user_id,movie_id,rating,timestamp\".split(\",\"))\n",
    "training_set = np.array(training_set_df, dtype = 'int')\n",
    "test_set_df = pd.read_csv('ml-100k/u1.test', delimiter = '\\t',names=\"user_id,movie_id,rating,timestamp\".split(\",\"))\n",
    "test_set = np.array(test_set_df, dtype = 'int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dIQKjiAlqGdC"
   },
   "source": [
    "# Step - 3 : Analyse the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cCRuD3VoqGb6"
   },
   "outputs": [],
   "source": [
    "training_set_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gn1GrNdDqGb-"
   },
   "outputs": [],
   "source": [
    "training_set_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xwDfDthBqGdD"
   },
   "outputs": [],
   "source": [
    "test_set_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xG35AZ1aqGd4"
   },
   "source": [
    "# Step - 4 : Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RayCVmJgrdHz"
   },
   "source": [
    "## Feature Engineering\n",
    "\n",
    "We want to fill the missing values of the age in the dataset with the average age value for each of the classes. This is called data imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1VHWSiq4CLNW"
   },
   "outputs": [],
   "source": [
    "# Getting the number of users and movies\n",
    "nb_users = int(max(max(training_set[:,0]), max(test_set[:,0])))\n",
    "nb_movies = int(max(max(training_set[:,1]), max(test_set[:,1])))\n",
    "print(nb_users,nb_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "by-vtJ-MCP5X"
   },
   "outputs": [],
   "source": [
    "# Converting the data into an array with users in lines and movies in columns\n",
    "def convert(data):\n",
    "    new_data = []\n",
    "    for id_user in range(1, nb_users + 1):\n",
    "        id_movies = data[:,1][data[:,0] == id_user]\n",
    "        id_ratings = data[:,2][data[:,0] == id_user]\n",
    "        ratings = np.zeros(nb_movies)\n",
    "        ratings[id_movies - 1] = id_ratings\n",
    "        new_data.append(list(ratings))\n",
    "    return new_data\n",
    "training_list = convert(training_set)\n",
    "test_list = convert(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HDgwUcz4CWn3"
   },
   "outputs": [],
   "source": [
    "len(training_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CICCkuz-CZya"
   },
   "outputs": [],
   "source": [
    "len(training_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TJJbMLo_CfN4"
   },
   "outputs": [],
   "source": [
    "# Converting the data into Torch tensors\n",
    "training_torch = torch.FloatTensor(training_list)\n",
    "test_torch = torch.FloatTensor(test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jxlMr97iqGei"
   },
   "source": [
    "# Step - 5 : Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gSfgFEucgZ_Y"
   },
   "source": [
    "<center><img src=\"https://www.dropbox.com/s/i37mgynkrf1d3vb/supervised_flow_chart.png?raw=1\" height=300px width=1000px></img></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s7u71_Yj7iIx"
   },
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_zyebrQ3moR5"
   },
   "outputs": [],
   "source": [
    "# Done Above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1svSbe48rkAL"
   },
   "source": [
    "## Building a  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KKzr-_boqGes"
   },
   "outputs": [],
   "source": [
    "# Creating the architecture of the Neural Network\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(nb_movies, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "        self.fc3 = nn.Linear(10, 20)\n",
    "        self.fc4 = nn.Linear(20, nb_movies)\n",
    "        self.activation = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.activation(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "sae = AutoEncoder()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(sae.parameters(), lr = 0.01, weight_decay = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X_ZQilgtC1xR"
   },
   "outputs": [],
   "source": [
    "# Training the AutoEncoder\n",
    "nb_epoch = 20 # 200\n",
    "for epoch in range(1, nb_epoch + 1):\n",
    "    train_loss = 0\n",
    "    s = 0.\n",
    "    for id_user in range(nb_users):\n",
    "        input = Variable(training_torch[id_user]).unsqueeze(0)\n",
    "        target = input.clone()\n",
    "        if torch.sum(target.data > 0) > 0:\n",
    "            output = sae(input)\n",
    "            target.require_grad = False\n",
    "            output[target == 0] = 0\n",
    "            loss = criterion(output, target)\n",
    "            mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
    "            loss.backward()\n",
    "            train_loss += np.sqrt(loss.item()*mean_corrector)\n",
    "            s += 1.\n",
    "            optimizer.step()\n",
    "    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vR440WOk8Gpm"
   },
   "source": [
    "## Predict using Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S8bdMGNbqGet"
   },
   "outputs": [],
   "source": [
    "# Testing the SAE\n",
    "test_loss = 0\n",
    "s = 0.\n",
    "for id_user in range(nb_users):\n",
    "    input = Variable(training_torch[id_user]).unsqueeze(0)\n",
    "    target = Variable(test_torch[id_user])\n",
    "    if torch.sum(target.data > 0) > 0:\n",
    "        output = sae(input)\n",
    "        output = sae(input).view(output.shape[1]) # did to this to get same shape as input\n",
    "        target.require_grad = False\n",
    "        output[target == 0] = 0\n",
    "        loss = criterion(output, target)\n",
    "        mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
    "        test_loss += np.sqrt(loss.item()*mean_corrector)\n",
    "        s += 1.\n",
    "print('test loss: '+str(test_loss/s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_YKIZMdEqGev"
   },
   "source": [
    "Let's move on to evaluate our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MxQbphc5r2fF"
   },
   "source": [
    "# Step - 6 : Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ctxrXoy3DLaB"
   },
   "outputs": [],
   "source": [
    "print('test loss: '+str(test_loss/s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c5i2Cgv8DTE5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "n0xmcHwoq2RJ",
    "WsxNikbDKadm",
    "lgi4ItFDp8PB",
    "cUnOm_5Sq8GT",
    "QbYMguutw0U7",
    "2Rpa7e44q9hG",
    "pLaE28PNqGcB",
    "IMJIkyRlqGch",
    "bwlH7SZAqGc1",
    "dIQKjiAlqGdC",
    "bzBbQPjTqGd3",
    "xG35AZ1aqGd4",
    "RayCVmJgrdHz",
    "oR-3amnaqGeO",
    "jxlMr97iqGei",
    "1svSbe48rkAL",
    "MxQbphc5r2fF",
    "FtA5kul0qGew",
    "oFrtqs9vqGez",
    "T_fkmW6Lr5sc",
    "8jw68DIRqGfH"
   ],
   "name": "SS - Auto Encoders.ipynb",
   "private_outputs": true,
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
